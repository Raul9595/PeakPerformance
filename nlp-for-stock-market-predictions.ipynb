{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Hey Folks!! This notebook will go over a method of predicting the Increase or Decrease of a the stock market with the help of Natural Language Processing techniques using the [scikit-learn](http://scikit-learn.org/stable/) library and the [Word2Vec](https://code.google.com/archive/p/word2vec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "stock_data = pd.read_csv(\"../input/DJIA_table.csv\") \n",
    "news_data = pd.read_csv(\"../input/RedditNews.csv\") \n",
    "news_data = news_data.merge(stock_data, on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the special characters\n",
    "news_data['News'] = [re.sub(r'\\W', ' ', row) for row in news_data['News']]\n",
    "\n",
    "# Remove all single characters\n",
    "news_data['News'] = [re.sub(r'\\s+[a-zA-Z]\\s+', ' ', row) for row in news_data['News']]\n",
    "\n",
    "# Remove single characters from the start\n",
    "news_data['News'] = [re.sub(r'\\^[a-zA-Z]\\s+', ' ', row) for row in news_data['News']]\n",
    "\n",
    "# Substituting multiple spaces with single space\n",
    "news_data['News'] = [re.sub(r'\\s+', ' ', row, flags=re.I) for row in news_data['News']]\n",
    "\n",
    "# Removing prefixed 'b'\n",
    "news_data['News'] = [re.sub(r'^b\\s+', '', row) for row in news_data['News']]\n",
    "\n",
    "# Removing numbers\n",
    "news_data['News'] = [re.sub(r'\\d+', '', row) for row in news_data['News']]\n",
    "\n",
    "news_data['News'] = [row.lower().split() for row in news_data['News']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Creates new Dataframe which contains the required columns\n",
    "grouped_news = pd.DataFrame(columns=['Date','Stacked News','Open','High','Low','Close','Volume','Adj Close'])\n",
    "grouped_news['Date'] = news_data.groupby('Date')['Date'].apply(set)\n",
    "grouped_news['Stacked News'] = news_data.groupby('Date')['News'].apply(list)\n",
    "grouped_news['Open'] = news_data.groupby('Date')['Open'].unique()\n",
    "grouped_news['High'] = news_data.groupby('Date')['High'].unique()\n",
    "grouped_news['Low'] = news_data.groupby('Date')['Low'].unique()\n",
    "grouped_news['Close'] = news_data.groupby('Date')['Close'].unique()\n",
    "grouped_news['Volume'] = news_data.groupby('Date')['Volume'].unique()\n",
    "grouped_news['Adj Close'] = news_data.groupby('Date')['Adj Close'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_news['Date'] = grouped_news['Date'].astype(str)\n",
    "grouped_news['Date'] = [row.strip(\"{}''\") for row in grouped_news['Date']]\n",
    "\n",
    "grouped_news['Open'] = grouped_news['Open'].astype(str)\n",
    "grouped_news['Open'] = [row.strip(\"[]\") for row in grouped_news['Open']]\n",
    "grouped_news['Open'] = grouped_news['Open'].astype(float)\n",
    "\n",
    "grouped_news['High'] = grouped_news['High'].astype(str)\n",
    "grouped_news['High'] = [row.strip(\"[]\") for row in grouped_news['High']]\n",
    "grouped_news['High'] = grouped_news['High'].astype(float)\n",
    "\n",
    "grouped_news['Low'] = grouped_news['Low'].astype(str)\n",
    "grouped_news['Low'] = [row.strip(\"[]\") for row in grouped_news['Low']]\n",
    "grouped_news['Low'] = grouped_news['Low'].astype(float)\n",
    "\n",
    "grouped_news['Close'] = grouped_news['Close'].astype(str)\n",
    "grouped_news['Close'] = [row.strip(\"[]\") for row in grouped_news['Close']]\n",
    "grouped_news['Close'] = grouped_news['Close'].astype(float)\n",
    "\n",
    "grouped_news['Volume'] = grouped_news['Volume'].astype(str)\n",
    "grouped_news['Volume'] = [row.strip(\"[]\") for row in grouped_news['Volume']]\n",
    "grouped_news['Volume'] = grouped_news['Volume'].astype(float)\n",
    "\n",
    "grouped_news['Adj Close'] = grouped_news['Adj Close'].astype(str)\n",
    "grouped_news['Adj Close'] = [row.strip(\"[]\") for row in grouped_news['Adj Close']]\n",
    "grouped_news['Adj Close'] = grouped_news['Adj Close'].astype(float)\n",
    "\n",
    "grouped_news['Increase/Decrease'] = grouped_news['Close'].diff()\n",
    "grouped_news.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "\n",
    "#Implementing the Word2Vec model\n",
    "for itr,row in enumerate(grouped_news['Stacked News']):\n",
    "    model = gensim.models.Word2Vec(grouped_news['Stacked News'][itr], size=300, window=5, min_count=1, workers=4)\n",
    "    grouped_news['Stacked News'][itr] = [model[word] for word in grouped_news['Stacked News'][itr]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_news['Vectorized News'] = grouped_news['Stacked News']\n",
    "for itr,row in enumerate(grouped_news['Vectorized News']):\n",
    "    grouped_news['Vectorized News'][itr] = [np.mean(array) for array in grouped_news['Vectorized News'][itr]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the mean of the vectorized words for each set\n",
    "for itr,row in enumerate(grouped_news['Vectorized News']):\n",
    "    min = np.min(grouped_news['Vectorized News'][itr])\n",
    "    max = np.max(grouped_news['Vectorized News'][itr])\n",
    "    grouped_news['Vectorized News'][itr] = [(row-min)/(max-min) for row in grouped_news['Vectorized News'][itr]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_news['Vectorized News'] = [np.mean(list_array) for list_array in grouped_news['Vectorized News']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_news_copy = grouped_news.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_news_copy.drop(['Date', 'Stacked News', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "       'Adj Close', 'Increase/Decrease'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Reg, X_test_Reg, y_train_Reg, y_test_Reg = train_test_split(grouped_news_copy, grouped_news['Increase/Decrease'].astype('int'), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "my_model_Reg = XGBRegressor()\n",
    "my_model_Reg.fit(X_train_Reg, y_train_Reg.astype('int'), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_Reg = my_model_Reg.predict(X_test_Reg)\n",
    "print(\"Mean Absolute Error for Regression : \", mean_absolute_error(y_test_Reg, predicted_Reg))\n",
    "print(\"Root Mean Squared Error for Regression : \", np.sqrt(mean_squared_error(y_test_Reg, predicted_Reg)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
